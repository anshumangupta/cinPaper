%\documentclass[9pt,pageno,twocolumn]{article}
\documentclass[twocolumn]{article}

\usepackage{comment}
\usepackage[top=1in, bottom=0.8in, left=1in, right=1in]{geometry}
\usepackage{graphicx}

\begin{document}

\title{Liberating Internet From The Clutches of Datacenter Oligarchy \\
Through Computation-In-Network (Coin)}
\author{Anshuman Gupta\\University of California, San Diego \\ anshuman@ucsd.edu}
% \author{Anshuman Gupta\\University of California, San Diego}
\date{}

\maketitle

\thispagestyle{empty}
\pagestyle{empty}

\begin{comment}
The internet has altered computers forever. Computers are no longer standalone
machines but part of a global connected community that shares knowledge and
resources. This has led to the conception of entirely new ecosystems such as the
datacenter-centric cloud computing, internet-of-things etc.
\end{comment}

Cloud computing has gained significant traction over the last decade and it
is becoming increasingly evident that globally data is slowly gravitating towards
datacenters operated by cloud service providers. Unfortunately this trend is
leading to the creation of a \textit{Datacenter-Oligarchy}, or an internet
organization in which datacenters are occupying an increasingly elite position.
Already datacenters are being used as the remote-host-of-choice for several
applications, and an increasing ratio of the internet traffic is being routed
to/from these datacenters. This ongoing reorganization threatens the freedom
of internet as a few datacenters might end up controlling vast portions of the
global data through lock-ins. Moreover, this also increases vulnerability of
users' private data present in clouds as the high concentration of information
in datacenters makes them attractive targets for \textit{Data Invasions} as
evident from the large number of unauthorized attempts to breach datacenters
as well as government metadata accesses in the recent past.

A datacenter-oligarchy can also lead to inefficiencies in the future: Firstly,
it increases communication costs, such as energy, latency, and bandwidth consumption.
For example, while sharing data across neighboring buildings, the energy required
to communicate with a remote datacenter is a wastage. Secondly, this increases the
variability in the networked-application behavior as its communication can be
disrupted due to congestion in the network anywhere between the client and its
datacenter. Therefore, freedom and equality must be restored in the internet for
the sake of security as well as efficiency.

\begin{figure*}
\includegraphics[keepaspectratio=yes,width=6in]{CoinArch.pdf}
\vspace*{-5mm}
\caption{Coin (Computation In Network) framework can lead to a more equitable
    distribution of data and computation over internet saving it from the
    dominance of datacenters.}
\label{fig:coinArch}
\vspace*{-2mm}
\end{figure*}

\textit{Insight}: Enabling in-network computation, instead of limiting computations
to only end-hosts or datacenters, will affect a more equitable distribution of
computation and data on the internet, as shown in Figure ~\ref{fig:coinArch}.
This redistribution of computational workload will reduce the data lock-ins and
information-density at datacenters, which will not only reduce the sensitivity
and influence of datacenters in the internet, but will also result in reduced
latencies, energy consumption, and bandwidth requirements in the network.

\vspace*{-3mm}
\section*{Coin: Computation-In-Network}
We propose \textit{Coin}, a computation-in-network framework to push internet
towards a more equitable organization. Cloud applications send and receive
packets over the internet routers that contain information required for triggering
computations in datacenters. In Coin, the routers intercept these packets to
determine the computations that needs to be done at the datacenter. If sufficient
resources, such as compute capability, code, and data, are available at the router
itself, it performs those computations in-situ. It then takes the necessary next
steps, such as send the response back, notify the datacenter, notify another
node on internet, etc. The datacenter as well as cloud clients are aware of
the compute-in-network capability, but do not necessarily rely on it.

Coin's network components provide the mechanisms for in-network computation, but
the actual location of any computation is a policy decision and should be determined
dynamically. The net effect of Coin is that the computations can be done anywhere
on the internet leading to the creation of an \textit{internet scale computer} with
no vulnerable points or lock-ins. On choosing appropriate policies, the computations,
and the corresponding data, will gradually migrate closer to the communicating agents,
rather than staying tethered to the datacenters, mimicing caching in existing computers
and leading to greatly improved performance and energy-efficiency of this internet scale
computer.

\vspace*{3mm}
\textbf{Code}: The Coin network nodes need to know the application code to be executed.
Because of the vast codebase of all possible network applications, it is not feasible to
store the code of every application inside every network node. These are a few approaches
for solving this problem:
\begin{itemize}
\item \textit{Coin Libraries (CoiLs)}: While there exists a large and ever-increasing code
base, there are algorithmic kernels reused across many applications. It is possible to
compile a kernel of these algorithms into multiple dynamic shared libraries, which can be
cached at Coin routers. Applications can exploit Coin by using these libraries and sending
network requests containing markups that encode which library functions have been executed
already, and which remain.
\item \textit{Active Messages}: Depending on the size of code to be executed in network, an
application can inscribe the relevant code section in the network request itself. However,
this can swell the request size and exacerbate the bandwidth and energy costs. Thus, in order
to get a favorable tradeoff between costs of code-embedding and savings of in-network
computation, applications need to cleverly determine when to use Coin.
\item \textit{Kernel ASICs}: Application code can be embedded into network processors (or
co-processors) by using specialized ASICs. These ASICs can be accessed by application code
either explicitly by calling an associated signature, or implicitly by matching the semantics
of application code segment with semantics of the available ASICs.
\end{itemize}

\textbf{Data}: A Coin router needs to obtain the input data for executing code. While some
of this data might be already present in network packets, it might be insufficient to
complete the computation. There are multiple approaches to obtain the remaining data:
\begin{itemize}
\item \textit{Global Coin Cache}: Coin routers can be augmented with storage, which can
act as a cache for incoming data. The application code can look for the required data,
not present in the network packet, in this cache and complete the computation on a cache
hit. Coin would require a global indexing/addressing (spanning space, time, and applications)
to enable accesses into this global cache. Moreover, due to limited storage capacity, clever
distributed cache replacement algorithms are required to determine which data to retain
and which to evict when the storage is full.
\item \textit{Waiting Buffers}: An application can send packets explicitly requesting
in-network processing along with the required data. These packets may contain information
about the source of data. If the router expects to receive data from this source, it can
temporarily retain the packet in waiting buffers. Otherwise it can forward the packet
to the stream that it estimates to be the closest to the source. If the packet is retained
in the waiting buffers for longer than an expiration period, it is forwarded to an
appropriate stream.
\item \textit{In-Network Data Requests}: If a router deems that there is a favorable tradeoff
in retrieving the data for this packet’s computation as well as future computations, the router
sends an in-network data request to the source, performs computation on current packet, and
retains the data for future in-network computations.
\end{itemize}

% Conclusion
The growing influence of datacenters in modern web-applications can jeopardize the flexibility
and openness of internet. This is an opportune time when we can exploit the abundant computational
capacity in the network to kill datacenter-oligarchy in its infancy and bring back equity in the
internet.

% \bibliographystyle{plain}
% \bibliography{references}


\end{document}

\begin{comment}
\begin{abstract}
Datacenters will continue to provide increasingly cost-effective services through
consolidation over internet accessible by cheap mobile devices. However, remote
computation at datacenters will put lower limits on physical network costs, such as
energy and latency. For example, even when video conferencing with a person in the
next building, a slowdown in a distant network link can disrupt the communication.
Moreover, the energy required by network packets to make a round-trip to the
datacenter in this case is an unnecessary wastage. These lower bounds on commnication
penalties can be overcome by enabling in-network computation, preferably at the
closest connecting node, to mitigate the network limits. This should result in reduced
latencies, reduced energy consumptions, and reduction in network bandwidth requirements.
\end{abstract}

\section*{Compute-In-Network (CIN)}
We propose creating a framework to enable in-network computation.
The framework spans from the internet access devices, to network routers, to the
datacenters. Applications running on the internet access devices, such as smartphone,
tablet, laptop, etc., send and receive packets over the internet. These packets
contain information required for triggering computations in datacenters. It is the
responsibility of internet routers to transport the packets between access devices
and datacenters. However, in this framework, the intermediate internet routers
intercept these packets to determine the computations that needs to be done for
these packets at the datacenter. If sufficient resources, such as compute capability,
code, data, etc., are available at the router itself, it performs those computations
in-situ. It can then take the necessary next step for the packet, such as send the
response back, notify the datacenter, notify another node on internet, etc. The
datacenter as well as access devices are aware of the compute-in-network capability,
but do not necessarily rely on it.

We now give a description of the various components of the framework here along with
their expected attributes for the framework. We present the current state of these
components and possible directions to enhance these components to meet the framework
requirements.

\textbf{Compute}: Network nodes must be capable of doing computations. Current
network switches/routers feature limited compute capacity for routing, diagnostics,
etc. However, these routers are not designed for executing generic application code.
Therefore, these routers need to augmented with enhanced compute capability for
enabling in-network computation. There are multiple approaches for this:
\begin{itemize}
\item \textit{General-Purpose Network Processors}: While current network routers and
switches aren’t sufficiently capable, with the advent of Software Defined Network (SDN)
and its rising popularity, network processors are expected to become increasingly
capable in future networks providing an opportunity to easily augment them for compute
in-network.
\item \textit{Commodity Co-Processors}: We can enhance the existing network routers
with commodity co-processors to enable in-network computation. There exists several
compute co-processors in the market that promise high throughput and energy-efficiency,
such as NVIDIA Tesla, Xeon Phi, Tile Gx, etc., which can be used to execute the
application code; these architectures can be further optimized for executing in-network
code.
\item \textit{Specialized Co-Processors}: There is a lot of existing work for designing
specialized co-processors that execute code kernels on dedicated ASICs to provide
significantly higher performance and energy-efficiency. It is possible to design
specialized network co-processors by extracting a kernel for datacenter application
code to provide further reductions in network latency and energy.
\end{itemize}

% \textbf{Salient Features}: 
We expect Coin to have the following salient features that will not only determine the
overall framework design, but will also trickle down to individual framework components:
\begin{itemize}
\item \textit{Programmability}: Coin should not increase programming complexity by
putting the burden of code-execution-point determination on the programmer, and should keep
the in-network computation functionality invisible to the end-user by default. However, to
enable an application programmer to exploit the improvement in response time, this
functionality should be exposed using a well-defined API.
\item \textit{Composability}: Coin should support modularity, i.e. the 
components should have well-defined interfaces (or API) that allow straightforward composition
of Coin components with legacy components. Moreover, as the framework evolves, the
components will become increasingly heterogeneous. Coin's modularity should enable
elegant composition of heterogeneous components as well.
\item \textit{Flexibility}: Coin should clearly distinguish between mechanisms (data-plane) and
policies (control-plane). Moreover, while the mechanisms can be embedded in hardware for reducing
latency and energy, policies must remain in software and should have small footprint in order to
enable fast policy changes.
\item \textit{Extensibility}: Networks are not static and are continuously growing. Therefore,
the framework design should be scalable in terms of latency, energy, and bandwidth.
\end{itemize}

\end{comment}

